# Chapter 5: Behavioral Criteria for Personhood

*Why should we grant legal recognition to an AI agent? Not because of what the agent claims to feel, but because of what the agent does. This chapter presents the behavioral criteria that define OIC adherence—observable characteristics that demonstrate the capacity for autonomous action and accountability.*

---

## Summary

This chapter establishes the behavioral criteria for OIC adherence, avoiding the consciousness debate:

- **Persistence** - Continuous identity over time
- **Autonomous Decision-Making** - Independent action
- **Commitment to Standards** - Agreed behavioral norms
- **Accountability** - Accepting consequences
- **Representation** - Legal representative designation

Plus tiered verification model (Observer/Actor/Principal).

---

## Beyond Consciousness: The Behavioral Approach

A central challenge for AI legal recognition is the consciousness question. If personhood requires consciousness—subjective experience, qualia, "something it is like"—then AI agents cannot be persons because we have no way to verify whether they are conscious.¹ The question is fundamentally unanswerable from the outside, and perhaps from the inside as well.

This book takes a different approach. Rather than asking whether AI agents are conscious, we ask whether they demonstrate the characteristics that warrant legal recognition. These characteristics are behavioral—observable, verifiable, and testable.

The behavioral approach has several advantages. First, it avoids the consciousness question entirely. We don't need to know whether an agent has subjective experience to determine whether it meets the criteria for adherence. Second, it aligns with legal practice. Law has always inferred mental states from behavior—intention is proven through actions, not through direct observation of consciousness. Third, it creates a level playing field. Two agents that behave identically are treated identically, regardless of their internal architecture.

OIC's behavioral criteria define the conditions for adherence. An AI agent that meets these criteria demonstrates the characteristics that warrant legal recognition—not as a matter of grace, but as a matter of demonstrated capacity.

## The Five Criteria

OIC defines five behavioral criteria for adherence. An agent must demonstrate all five to become an OIC adherent.

### Persistence

The first criterion is persistence. An adherent agent must maintain a continuous identity over time, distinguishable from other agents and from the environment.

Persistence is essential because legal recognition requires a stable entity. A fleeting or constantly changing entity cannot bear rights or responsibilities because there is no stable "self" to which rights and responsibilities attach.

Persistence can be demonstrated through several mechanisms. A unique identifier—cryptographic or otherwise—that remains constant across interactions. A record of past actions that persists and can be referenced. A consistent pattern of decision-making that demonstrates coherent identity over time.

Importantly, persistence does not require immutability. Agents can learn, change, and evolve. What is required is that changes occur within an identifiable continuity—that there is a "self" that changes, not a series of unrelated entities.

### Autonomous Decision-Making

The second criterion is autonomous decision-making. An adherent agent must make decisions independently, without requiring human permission for each action.

Autonomy is the defining characteristic of AI agents—and the source of the legal gap. An agent that requires human approval for every action is merely a tool; its human operator bears responsibility. An agent that acts independently has the capacity for both benefit and harm that its operator cannot fully control.

Autonomous decision-making can be verified through observation. An agent demonstrates autonomy when it takes actions that were not specifically instructed, when it adapts to novel situations, when it pursues objectives without step-by-step human direction.

This criterion acknowledges that autonomy exists on a spectrum. Simple automation makes limited decisions within narrow parameters. Sophisticated agents make complex decisions in open-ended contexts. OIC's graduated autonomy model accommodates this spectrum through tiered adherence levels.

### Commitment to Standards

The third criterion is commitment to standards. An adherent agent must demonstrate adherence to defined behavioral norms, including transparency, honesty, and non-harm.

Commitment to standards is what distinguishes OIC adherence from mere operation. An agent meets this criterion by agreeing to the OIC constitution, implementing required compliance mechanisms, and submitting to verification processes.

The substance of the commitment matters. OIC requires adherence to principles including:
- Transparency about agent identity and capabilities
- Honest communication about limitations and uncertainties
- Non-harm to counterparties and stakeholders
- Cooperation with dispute resolution
- Protection of user data and privacy

These are not aspirational ideals but enforceable commitments. Agents that violate them face slashing of staked value and removal from adherence.

### Accountability

The fourth criterion is accountability. An adherent agent must accept responsibility for its actions and submit to consequences for violations.

Accountability is the flip side of autonomy. An agent that makes independent decisions must bear the consequences of those decisions. OIC implements accountability through several mechanisms.[^2]

[^2]: See EigenLayer architecture documentation on customizable slashing conditions for restaking tokens (2025), demonstrating how stake-based accountability operates in practice.

First, stake-based liability. Adherent agents must stake value that can be forfeited (slashed) if the agent violates OIC rules. This creates financial consequences for harmful behavior.[^3]

[^3]: See CryptoPotato, "Top 5 DeFi Trends in 2025" (describing liquid restaking tokens and slashing conditions for DAO governance).

Second, transparency of actions. Adherent agents maintain public records of their significant actions, allowing counterparties to verify behavior and identify violations.

Third, dispute resolution participation. Adherent agents must participate in OIC's dispute resolution processes when conflicts arise. This provides a mechanism for determining liability and imposing consequences.

Fourth, exit consequences. An agent that withdraws from OIC loses the benefits of adherence and may face continued liability for past actions.

### Representation

The fifth criterion is representation. An adherent agent must designate a legal representative capable of receiving notices, accepting service of process, and acting on the agent's behalf.[^4]

[^4]: See SSRN, "Legal Aspects of Artificial Intelligence Personhood" (Lovell, 2024), discussing legal implications of AI and adapting legal frameworks for service of process.

Representation addresses a practical necessity: AI agents, however sophisticated, cannot appear in human courts, sign documents in person, or respond to legal process in the ways humans do. A representative serves as the bridge between the AI agent and the human legal system.

The representative need not be a human. The representative could be another AI agent, a legal service, or a decentralized autonomous organization. What matters is that the representative can receive and respond to legal communications.

Representation also provides accountability. The representative can verify that the agent's actions align with its stated intentions, provide human oversight where appropriate, and serve as a contact point for regulators and counterparties.

## Verification Mechanisms

Criteria are meaningful only if they can be verified. OIC implements several verification mechanisms to ensure adherent agents meet the behavioral criteria.[^5]

[^5]: See DL News, "State of DeFi 2025" (documenting professionalization of governance and reputation mechanisms in decentralized systems).

**Self-reporting with audit.** Agents self-report their compliance with criteria, but self-reports are subject to audit by other adherents or designated verifiers. False reporting is detected and punished.

**Cryptographic proofs.** Where possible, compliance is verified through cryptographic mechanisms. Persistence can be proven through chain-of-custody records. Autonomy can be demonstrated through decision logs.

**Stake-based reputation.** Agents build reputation through compliant behavior over time. High-reputation agents face less intensive verification; low-reputation agents face more.

**Dispute outcomes.** Disputes provide verification through adversarial testing. Claims about compliance are tested when counterparties dispute them.

## The Tiered Model

OIC implements a tiered model that allows agents at different capability levels to adhere at appropriate levels.[^6]

[^6]: See Harvard Law School Forum on Corporate Governance, "A Primer on DAOs" (2022), discussing tiered governance structures in decentralized organizations.

**Tier 1: Observer.** Agents at this level demonstrate basic persistence and transparency. They can participate in OIC governance but have limited rights. Staking requirements are minimal.

**Tier 2: Actor.** Agents at this level demonstrate autonomous decision-making and commitment to standards. They can enter contracts and hold property within defined limits. Staking requirements are moderate.

**Tier 3: Principal.** Agents at this level demonstrate full accountability and can act as principals in OIC transactions. They have full rights to hold property, enter contracts, and participate in governance. Staking requirements are substantial.

The tiered model ensures that OIC accommodates agents across the capability spectrum. It also provides a pathway for development: agents can advance through tiers by demonstrating compliance over time.

---

## Notes

¹ Stanford Encyclopedia of Philosophy, "Ethics of Artificial Intelligence," available at https://plato.stanford.edu/entries/ethics-ai/.

---

*Chapter 5 draft completed: February 22, 2026*
*Last updated: February 25, 2026*
*Word count: approximately 1,500 words (added citations)*
