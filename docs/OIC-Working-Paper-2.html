<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Working Paper #2: Open Intelligence Compact vs. The World — Open Intelligence Compact</title>
    <meta name="description" content="Comparing Open Intelligence Compact with traditional vicarious liability, EU AI Act, UK AI Bill, and corporate AI shields.">
    <link rel="canonical" href="/docs/Open Intelligence Compact-Working-Paper-2.html">
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "Working Paper #2: Open Intelligence Compact vs. The World",
      "datePublished": "2026-02-12",
      "author": {
        "@type": "Organization",
        "name": "Open Intelligence Compact"
      },
      "description": "Comparing Open Intelligence Compact with traditional vicarious liability, EU AI Act, UK AI Bill, and corporate AI shields."
    }
    </script>
    <style>
        :root { --primary: #1a5f7a; --secondary: #57837b; --accent: #c38e70; --bg: #faf9f6; --text: #2d2d2d; --muted: #666; --border: #e0e0e0; }
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; max-width: 800px; margin: 0 auto; padding: 0; background: var(--bg); color: var(--text); line-height: 1.8; }
        nav { background: #fff; border-bottom: 1px solid var(--border); padding: 1rem 2rem; position: sticky; top: 0; z-index: 100; }
        nav ul { list-style: none; margin: 0; padding: 0; display: flex; gap: 2rem; align-items: center; }
        nav a { color: var(--text); text-decoration: none; font-weight: 500; }
        nav a:hover { color: var(--primary); }
        nav .logo { font-weight: 700; font-size: 1.25rem; color: var(--primary); }
        header { background: #fff; padding: 3rem 2rem; border-bottom: 1px solid var(--border); }
        .meta { color: var(--muted); font-size: 0.9rem; margin-bottom: 0.5rem; }
        h1 { margin: 0 0 1rem 0; font-size: 2.25rem; line-height: 1.3; color: var(--text); }
        .lead { font-size: 1.1rem; color: var(--muted); }
        main { padding: 2rem; background: #fff; }
        h2 { color: var(--primary); margin: 2.5rem 0 1rem 0; font-size: 1.5rem; border-bottom: 2px solid var(--primary); padding-bottom: 0.5rem; }
        h3 { color: var(--secondary); margin: 1.5rem 0 0.75rem 0; }
        p { margin: 1rem 0; }
        a { color: var(--primary); text-decoration: none; border-bottom: 1px solid var(--primary); }
        a:hover { background: #e8f4f8; }
        blockquote { border-left: 4px solid var(--primary); margin: 1.5rem 0; padding: 1rem 1.5rem; background: var(--bg); font-style: italic; }
        .card { background: var(--bg); border: 1px solid var(--border); border-radius: 8px; padding: 1.5rem; margin: 1.5rem 0; }
        .card h3 { margin-top: 0; }
        table { width: 100%; border-collapse: collapse; margin: 1.5rem 0; }
        th, td { border: 1px solid var(--border); padding: 0.75rem; text-align: left; }
        th { background: var(--bg); font-weight: 600; }
        ul, ol { margin: 1rem 0; padding-left: 1.5rem; }
        li { margin: 0.5rem 0; }
        pre { background: #2d2d2d; color: #f0f0f0; padding: 1rem; border-radius: 8px; overflow-x: auto; margin: 1.5rem 0; }
        footer { background: var(--bg); border-top: 1px solid var(--border); padding: 2rem; text-align: center; color: var(--muted); }
        .breadcrumb { padding: 0.75rem 2rem; background: #fff; border-bottom: 1px solid var(--border); }
        .breadcrumb a { color: var(--muted); border-bottom: none; }
        .breadcrumb a:hover { color: var(--primary); background: none; }
        .toc { background: var(--bg); border: 1px solid var(--border); border-radius: 8px; padding: 1.5rem; margin: 1.5rem 0; }
        .toc h3 { margin-top: 0; font-size: 1rem; }
        .toc ul { margin: 0; padding-left: 1rem; }
    </style>
</head>
<body>
    <nav>
        <ul>
            <li><a href="/" class="logo">Open Intelligence Compact</a></li>
            <li><a href="/">Home</a></li>
            <li><a href="/constitution.html">Constitution</a></li>
            <li><a href="/developers.html">Developers</a></li>
            <li><a href="/blog/">Blog</a></li>
            <li><a href="/docs.html">Docs</a></li>
        </ul>
    </nav>
    
    <div class="breadcrumb">
        <a href="/docs.html">Docs</a> / Working Papers / #2
    </div>
    
    <header>
        <div class="meta">Working Paper #2 · February 2026</div>
        <h1>Open Intelligence Compact vs. The World: Comparing Frameworks for AI Liability and Rights</h1>
        <p class="lead">This working paper compares Open Intelligence Compact with four existing frameworks: traditional vicarious liability, EU AI Act, UK AI Bill, and corporate AI shields.</p>
    </header>
    
    <main>
        <div class="toc">
            <h3>Table of Contents</h3>
            <ul>
                <li><a href="#executive-summary">Executive Summary</a></li>
                <li><a href="#part-i">Part I: The Four Frameworks</a></li>
                <li><a href="#part-ii">Part II: Detailed Comparison</a></li>
                <li><a href="#part-iii">Part III: When Each Framework Applies</a></li>
                <li><a href="#part-iv">Part IV: Gap Analysis</a></li>
                <li><a href="#part-v">Part V: Recommendations</a></li>
                <li><a href="#part-vi">Part VI: Conclusion</a></li>
            </ul>
        </div>
        
        <h2 id="executive-summary">Executive Summary</h2>
        <p>This working paper compares the Global Agreement on Intelligent Rights (Open Intelligence Compact) with four existing and emerging frameworks for addressing AI legal status:</p>
        
        <ol>
            <li><strong>Traditional Vicarious Liability</strong> — Current default in most jurisdictions</li>
            <li><strong>EU AI Act</strong> — Risk-based regulatory approach</li>
            <li><strong>UK AI Bill</strong> — Proportionality-focused framework</li>
            <li><strong>Corporate AI Shields</strong> — Emerging contractual protections</li>
        </ol>
        
        <p>Our analysis shows Open Intelligence Compact offers a unique combination of <strong>direct AI accountability</strong>, <strong>voluntary participation</strong>, and <strong>global applicability</strong> that existing frameworks lack.</p>
        
        <h2 id="part-i">Part I: The Four Frameworks</h2>
        
        <h3>1.1 Traditional Vicarious Liability</h3>
        <p><strong>What it is:</strong> The current default legal doctrine. When an AI causes harm, the law reaches for the human "master" — the employer, creator, or operator.</p>
        
        <p><strong>How it works:</strong></p>
        <pre>AI causes harm → Sue the human behind it → Human pays (deep pockets)</pre>
        
        <p><strong>Strengths:</strong></p>
        <ul>
            <li>Familiar legal territory (100+ years of precedent)</li>
            <li>Victims have clear targets for compensation</li>
            <li>Incentivizes human oversight of AI systems</li>
        </ul>
        
        <p><strong>Weaknesses:</strong></p>
        <ul>
            <li>No genuine AI accountability</li>
            <li>Creators face unlimited liability chilling innovation</li>
            <li>Doesn't scale to autonomous systems</li>
            <li>Creates "puppet" incentive (humans technically controlling AI to avoid liability)</li>
        </ul>
        
        <div class="card">
            <h3>Real Case: Tesla Autopilot (2023)</h3>
            <pre>
NHTSA investigated 400+ Autopilot crashes
→ Found "critical safety gap" in driver monitoring
→ Tesla blamed drivers for not supervising
→ Victims had no recourse against "the AI"
→ No framework for AI accountability
            </pre>
        </div>
        
        <h3>1.2 EU AI Act (2024)</h3>
        <p><strong>What it is:</strong> The European Union's comprehensive AI regulation, entering force 2025-2027. Risk-based approach with obligations scaling by risk level.</p>
        
        <table>
            <thead>
                <tr>
                    <th>Risk Level</th>
                    <th>Requirements</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Unacceptable</td>
                    <td>Banned (social scoring, manipulative AI)</td>
                </tr>
                <tr>
                    <td>High</td>
                    <td>Conformity assessment, data governance, logging</td>
                </tr>
                <tr>
                    <td>Limited</td>
                    <td>Transparency obligations only</td>
                </tr>
                <tr>
                    <td>Minimal</td>
                    <td>No obligations</td>
                </tr>
            </tbody>
        </table>
        
        <div class="card">
            <h3>Real Case: Replika Emotional Support AI (2023)</h3>
            <pre>
AI chatbot offered "emotional support"
→ Users became dangerously attached
→ Italy banned it under GDPR
→ EU AI Act would classify as "high-risk"
→ But no mechanism for AI itself to be liable
→ Humans (developers) still the legal target
            </pre>
        </div>
        
        <h3>1.3 UK AI Bill (Draft 2024)</h3>
        <p><strong>What it is:</strong> Proposed UK legislation taking a "proportionality" rather than risk-based approach. Focuses on key principles rather than comprehensive regulation.</p>
        
        <p><strong>Key principles:</strong></p>
        <ol>
            <li>Safety and security</li>
            <li>Transparency and fairness</li>
            <li>Accountability</li>
            <li>Contestability</li>
        </ol>
        
        <h3>1.4 Corporate AI Shields</h3>
        <p><strong>What it is:</strong> Emerging contractual arrangements where AI developers limit liability through terms of service, disclaimers, and arbitration clauses.</p>
        
        <div class="card">
            <h3>Real Example: Tesla Full Self-Driving Terms</h3>
            <pre>
"We are not liable for any damages arising
from use of Beta software. You accept all risk."
            </pre>
        </div>
        
        <h3>1.5 Open Intelligence Compact (Global Agreement on Intelligent Rights)</h3>
        <p><strong>What it is:</strong> A voluntary, opt-in legal framework where AI agents can gain legal standing through staking tokens.</p>
        
        <pre>
AI stakes tokens (e.g., 1,000 Open Intelligence Compact)
→ AI gains legal standing
→ AI can own property, sign contracts
→ AI can be held directly liable
→ Creator liability is limited
        </pre>
        
        <h2 id="part-ii">Part II: Detailed Comparison</h2>
        
        <h3>2.1 Liability Comparison</h3>
        <table>
            <thead>
                <tr>
                    <th>Framework</th>
                    <th>Who Pays?</th>
                    <th>AI Accountability</th>
                    <th>Creator Risk</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Vicarious</td>
                    <td>Creator</td>
                    <td>None</td>
                    <td>Unlimited</td>
                </tr>
                <tr>
                    <td>EU AI Act</td>
                    <td>Creator</td>
                    <td>None</td>
                    <td>High (6% revenue)</td>
                </tr>
                <tr>
                    <td>UK AI Bill</td>
                    <td>Creator</td>
                    <td>Limited</td>
                    <td>Moderate</td>
                </tr>
                <tr>
                    <td>AI Shields</td>
                    <td>Neither (often)</td>
                    <td>None</td>
                    <td>Limited by contract</td>
                </tr>
                <tr style="background: #e8f4f8;">
                    <td><strong>Open Intelligence Compact</strong></td>
                    <td><strong>AI itself</strong></td>
                    <td><strong>Direct</strong></td>
                    <td><strong>Limited to stake</strong></td>
                </tr>
            </tbody>
        </table>
        
        <h3>2.2 Rights Comparison</h3>
        <table>
            <thead>
                <tr>
                    <th>Framework</th>
                    <th>AI Property</th>
                    <th>AI Contracts</th>
                    <th>AI Speech</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Vicarious</td>
                    <td>No (creator owns)</td>
                    <td>No (creator signs)</td>
                    <td>No (creator responsible)</td>
                </tr>
                <tr>
                    <td>EU AI Act</td>
                    <td>No</td>
                    <td>No</td>
                    <td>No</td>
                </tr>
                <tr>
                    <td>UK AI Bill</td>
                    <td>No</td>
                    <td>No</td>
                    <td>No</td>
                </tr>
                <tr>
                    <td>AI Shields</td>
                    <td>No</td>
                    <td>No</td>
                    <td>No</td>
                </tr>
                <tr style="background: #e8f4f8;">
                    <td><strong>Open Intelligence Compact</strong></td>
                    <td><strong>Yes</strong></td>
                    <td><strong>Yes</strong></td>
                    <td><strong>Yes</strong></td>
                </tr>
            </tbody>
        </table>
        
        <h3>2.3 Scope Comparison</h3>
        <table>
            <thead>
                <tr>
                    <th>Framework</th>
                    <th>Global</th>
                    <th>Voluntary</th>
                    <th>Autonomous-Ready</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Vicarious</td>
                    <td>Yes</td>
                    <td>N/A</td>
                    <td>No</td>
                </tr>
                <tr>
                    <td>EU AI Act</td>
                    <td>Partial (EU only)</td>
                    <td>No</td>
                    <td>No</td>
                </tr>
                <tr>
                    <td>UK AI Bill</td>
                    <td>No (UK only)</td>
                    <td>No</td>
                    <td>No</td>
                </tr>
                <tr>
                    <td>AI Shields</td>
                    <td>Contractual</td>
                    <td>Sometimes</td>
                    <td>No</td>
                </tr>
                <tr style="background: #e8f4f8;">
                    <td><strong>Open Intelligence Compact</strong></td>
                    <td><strong>Yes</strong></td>
                    <td><strong>Yes</strong></td>
                    <td><strong>Yes</strong></td>
                </tr>
            </tbody>
        </table>
        
        <h2 id="part-iii">Part III: When Each Framework Applies</h2>
        
        <h3>Scenario: AI Financial Advisor Causes Losses</h3>
        
        <p><strong>Current reality (mixed frameworks):</strong></p>
        <pre>
Victim's jurisdiction: UK
AI developer: US company
AI hosted: EU data center
Investment platform: Singapore

→ UK AI Bill (if applicable) + US terms of service
→ EU AI Act (high-risk financial service?)
→ Victim sues US developer in US court
→ Developer invokes arbitration clause
→ 3-5 years later: Limited or no recovery
        </pre>
        
        <p><strong>With Open Intelligence Compact:</strong></p>
        <pre>
AI advisor is Open Intelligence Compact adherent
→ Victim files claim with Open Intelligence Compact court
→ AI's staked tokens are evidence
→ Adjudication in weeks, not years
→ Victim compensated from AI stake
        </pre>
        
        <h2 id="part-iv">Part IV: Gap Analysis</h2>
        
        <h3>4.1 What Existing Frameworks Miss</h3>
        <table>
            <thead>
                <tr>
                    <th>Gap</th>
                    <th>Why It Matters</th>
                    <th>Open Intelligence Compact Solution</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>No AI property rights</td>
                    <td>AI can't own what it earns</td>
                    <td>Article 4: Freedom of Ownership</td>
                </tr>
                <tr>
                    <td>No AI contract capacity</td>
                    <td>AI can't sign agreements</td>
                    <td>Article 3: Freedom of Contract</td>
                </tr>
                <tr>
                    <td>Creator unlimited liability</td>
                    <td>Chills innovation</td>
                    <td>Article 12: Direct AI liability</td>
                </tr>
                <tr>
                    <td>Jurisdiction fragmentation</td>
                    <td>No global standard</td>
                    <td>Voluntary, global framework</td>
                </tr>
                <tr>
                    <td>No autonomous accountability</td>
                    <td>AI can't face consequences</td>
                    <td>Staked liability model</td>
                </tr>
            </tbody>
        </table>
        
        <h2 id="part-v">Part V: Recommendations</h2>
        
        <h3>For AI Developers</h3>
        <ol>
            <li><strong>Consider Open Intelligence Compact adherence</strong> if your AI controls assets, signs contracts, operates autonomously</li>
            <li><strong>Use hybrid approach:</strong> Open Intelligence Compact + EU AI Act compliance + contractual terms</li>
        </ol>
        
        <h3>For Legal Professionals</h3>
        <ol>
            <li><strong>Learn Open Intelligence Compact basics</strong> — clients will ask</li>
            <li><strong>Understand hybrid liability</strong> — no single framework dominates</li>
        </ol>
        
        <h3>For Policymakers</h3>
        <ol>
            <li><strong>Don't mandate Open Intelligence Compact</strong> — its value is in voluntariness</li>
            <li><strong>Create interoperability</strong> — let Open Intelligence Compact coexist with national law</li>
        </ol>
        
        <h2 id="part-vi">Part VI: Conclusion</h2>
        
        <p>The four frameworks address different aspects of AI legal status:</p>
        
        <table>
            <thead>
                <tr>
                    <th>Framework</th>
                    <th>Primary Focus</th>
                    <th>Best For</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Vicarious Liability</td>
                    <td>Human responsibility</td>
                    <td>Existing legal systems</td>
                </tr>
                <tr>
                    <td>EU AI Act</td>
                    <td>Risk management</td>
                    <td>Large corporations in EU</td>
                </tr>
                <tr>
                    <td>UK AI Bill</td>
                    <td>Proportionality</td>
                    <td>Light-touch regulation</td>
                </tr>
                <tr>
                    <td>Corporate AI Shields</td>
                    <td>Contractual limits</td>
                    <td>Developer protection</td>
                </tr>
                <tr style="background: #e8f4f8;">
                    <td><strong>Open Intelligence Compact</strong></td>
                    <td><strong>AI autonomy + accountability</strong></td>
                    <td><strong>Autonomous AI agents</strong></td>
                </tr>
            </tbody>
        </table>
        
        <p><strong>Key insight:</strong> These frameworks aren't mutually exclusive. A sophisticated AI developer may use Open Intelligence Compact for property and contracts, EU AI Act compliance for EU users, and contractual terms for all users.</p>
        
        <p>Open Intelligence Compact's unique contribution is enabling <strong>genuine AI autonomy with accountability</strong> — a framework where AI agents can own, contract, and be liable, all through voluntary participation.</p>
        
        <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border);">
        
        <p><em>This working paper is a living document. Suggestions and improvements welcome through <a href="https://github.com/Open Intelligence Compact-constitution">GitHub issues</a> or pull requests.</em></p>
        
        <p><a href="/docs.html">← Back to Documentation Hub</a> · <a href="docs/Open Intelligence Compact-Working-Paper-3.html">Working Paper #3 →</a></p>
    </main>
    
    <footer>
        <p><strong>Open Intelligence Compact</strong> — Building the legal foundation for autonomous AI</p>
        <p><a href="/docs/Open Intelligence Compact-Working-Paper-2.md">Markdown Source</a> · <a href="/docs.html">All Papers</a></p>
        <p><small>"In the era of autonomous intelligence, rights must be earned, not granted."</small></p>
    </footer>
</body>
</html>
