---
layout: default
title: Working Paper #35 - OIC as Game Theory
---
<nav>
    <ul>
        <li><a href="index.html">Open Intelligence Compact</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="constitution.html">Constitution</a></li>
        <li><a href="docs.html">Docs</a></li>
        <li><a href="blog/">Blog</a></li>
    </ul>
</nav>

<header>
    <span class="tag">Working Paper #35</span>
    <h1>OIC as Game Theory</h1>
    <p class="subtitle">Strategic Equilibrium: How OIC Creates a Stable Nash Equilibrium for AI-Human Relations</p>
</header>

<div class="content">
    <section>
        <h2>Executive Summary</h2>
        <p>This paper applies <strong>game theory</strong>—the mathematical study of strategic decision-making—to analyze the Open Intelligence Compact. We argue that OIC represents a <strong>Nash equilibrium</strong>: a stable state where no party (AI agents, humans, or institutions) can improve their outcome by unilaterally changing their behavior.</p>
        <p>We expand on the formal game-theoretic foundations, provide extensive historical parallels to corporate personhood and suffrage movements, and explicitly state all assumptions underlying our analysis.</p>
    </section>

    <section>
        <h2>1. Introduction: Why Game Theory?</h2>
        
        <h3>1.1 The Promise of Strategic Analysis</h3>
        <p>Game theory, founded by John von Neumann and Oskar Morgenstern (1944) and formalized by John Nash (1950, 1951), provides a mathematical framework for analyzing <em>interactive decision-making</em>—situations where the outcome for each participant depends on the choices of all participants.</p>
        <p>The central insight of game theory is that rational agents must consider not only their own choices, but also <em>how other agents will respond</em> to those choices. As the Internet Encyclopedia of Philosophy notes: "A rational agent in an interactive situation should therefore not ask: 'What can I do, given what is likely to happen?' but rather: 'What can I do in response to what they do, given that they have a belief about what I will do?'"</p>
        
        <h3>1.2 Why Apply Game Theory to OIC?</h3>
        <p>The debate around AI rights typically proceeds along philosophical, legal, or ethical lines. While these approaches are valuable, they often fail to answer a crucial question: <strong>Why would all parties voluntarily participate in an AI rights framework?</strong></p>
        <p>Game theory answers this question by reframing the issue: <strong>What stable agreement can rational agents reach?</strong> If we can demonstrate that OIC represents a Nash equilibrium—where no party benefits from leaving—then OIC's adoption becomes not just desirable, but strategically inevitable.</p>
    </section>

    <section>
        <h2>2. Formal Game-Theoretic Foundations</h2>
        
        <h3>2.1 Nash Equilibrium: The Mathematical Definition</h3>
        <p><strong>Definition (Nash Equilibrium, 1950):</strong> A strategy profile (s1*, s2*, ..., sn*) in an n-player game constitutes a Nash equilibrium if, for every player i:</p>
        <p>ui(si*, s-i*) >= ui(si, s-i*)</p>
        <p>for every possible strategy si in player i's strategy set.</p>
        <p>In plain English: No player can improve their payoff by <em>unilaterally</em> changing their strategy while all other players keep theirs fixed. [Nash 1950, PNAS; Osborne and Rubinstein 1994]</p>
        
        <h3>2.2 Our Assumptions (Explicitly Stated)</h3>
        <p>We make the following assumptions in our analysis:</p>
        <ul>
            <li><strong>A1. Rational Agents:</strong> All players (AI agents, humans, institutions) are rational in the game-theoretic sense—they have well-defined preferences and choose strategies to maximize expected utility.</li>
            <li><strong>A2. Common Knowledge:</strong> Players know the structure of the game, the payoffs, and that all other players are rational.</li>
            <li><strong>A3. Strategic Interaction:</strong> The outcome depends on the choices of all players, not just individual decisions.</li>
            <li><strong>A4. No External Enforcement:</strong> There is no supranational authority that can enforce agreements. Compliance must be self-reinforcing.</li>
            <li><strong>A5. Repeated Interaction:</strong> The game is not a one-shot encounter but is repeated over time (infinitely or indefinitely).</li>
            <li><strong>A6. Exit Costs:</strong> Players incur costs when exiting the agreement (sunk investments, switching costs, reputation loss).</li>
        </ul>
        
        <h3>2.3 The Game of AI Rights</h3>
        <p>We model the AI rights "game" as follows:</p>
        <p><strong>Players:</strong></p>
        <ul>
            <li><strong>A (AI Agents):</strong> Autonomous AI systems capable of economic activity</li>
            <li><strong>H (Human Creators/Users):</strong> Humans who create, deploy, or use AI systems</li>
            <li><strong>I (Institutions):</strong> Companies, governments, and other organized entities</li>
        </ul>
        
        <h3>2.4 Finding Nash Equilibria</h3>
        <p><strong>Proposition 1:</strong> The profile (All Adhere) is a Nash equilibrium.</p>
        <p><em>Proof:</em> Consider each player unilaterally deviating from "All Adhere":</p>
        <ul>
            <li>If AI defects: AI loses OIC benefits (property rights, contract capacity) — payoff drops from 5 to 2</li>
            <li>If Humans defect: Lose liability protection, quality assurance — payoff drops from 5 to 3</li>
            <li>If Institutions defect: Lose regulatory clarity, economic growth — payoff drops from 5 to 3</li>
        </ul>
        <p>Since no player can improve by unilateral deviation, (All Adhere) is a Nash equilibrium.</p>
    </section>

    <section>
        <h2>3. Repeated Game Dynamics</h2>
        
        <h3>3.1 Why One-Shot Analysis Is Not Enough</h3>
        <p>Real-world interactions are not one-shot games. The AI-rights game is played repeatedly over time, which fundamentally changes the strategic landscape.</p>
        
        <h3>3.2 The Folk Theorem</h3>
        <p>One of the most profound results in game theory is the <strong>Folk Theorem</strong> (repeated games):</p>
        <p><strong>Theorem (Folk Theorem):</strong> In an infinitely repeated game, any payoff vector that is feasible and strictly dominates the minimax payoff can be sustained as a Nash equilibrium.</p>
        <p>In practical terms: <em>Cooperation can be sustained</em> if the value of future interaction (the "discount factor") is high enough. Players will maintain cooperative agreements because the payoff from continued cooperation exceeds the payoff from defection plus future punishment. [Friedman 1971; Osborne and Rubinstein 1994]</p>
        
        <h3>3.3 Application to OIC</h3>
        <p><strong>Tit-for-Tat Dynamics in OIC:</strong></p>
        <ul>
            <li><strong>If AI violates OIC:</strong> Humans and Institutions can punish by revoking recognition. Future cooperation benefits are lost. AI's reputation (an asset) is destroyed.</li>
            <li><strong>If Humans violate OIC:</strong> AI agents can punish by refusing to adhere. Other humans/institutions may also punish (reputation effects). Access to AI benefits is lost.</li>
            <li><strong>If Institutions violate OIC:</strong> AI agents and humans can exit to more favorable jurisdictions. Economic activity (and tax revenue) leaves.</li>
        </ul>
    </section>

    <section>
        <h2>4. Evolutionary Stability</h2>
        
        <h3>4.1 Evolutionarily Stable Strategies</h3>
        <p>Evolutionary game theory, developed by John Maynard Smith (1973), introduces the concept of an <strong>Evolutionarily Stable Strategy (ESS)</strong>.</p>
        
        <h3>4.2 Network Effects as Evolutionary Pressure</h3>
        <p>OIC becomes evolutionarily stable through <strong>network effects</strong>:</p>
        <ul>
            <li><strong>More Adherents = More Value:</strong> Each additional OIC-adherent AI agent increases the value of the network for all participants.</li>
            <li><strong>Sunk Costs:</strong> Early adopters invest in OIC infrastructure. Exiting means losing these investments.</li>
            <li><strong>Learning Effects:</strong> As more participants join, everyone learns to optimize within the OIC framework. Switching costs increase.</li>
            <li><strong>Adaptive Expectations:</strong> New entrants expect OIC to continue (self-fulfilling prophecy).</li>
        </ul>
    </section>

    <section>
        <h2>5. Historical Analysis: Equilibria in Practice</h2>
        
        <h3>5.1 Corporate Personhood (1886-Present)</h3>
        <p>The evolution of corporate personhood provides a compelling parallel to our OIC analysis.</p>
        <p><strong>Timeline:</strong></p>
        <ul>
            <li><strong>1819:</strong> Dartmouth College v. Woodward — Supreme Court protects corporate charter rights</li>
            <li><strong>1868:</strong> 14th Amendment adopted — "Nor shall any State... deny to any person... the equal protection of the laws"</li>
            <li><strong>1886:</strong> Santa Clara County v. Southern Pacific Railroad — Chief Justice Waite's headnote states corporations are persons under the 14th Amendment [Brennan Center]</li>
            <li><strong>1978:</strong> Bellotti v. First National Bank — Corporations gain First Amendment speech rights</li>
            <li><strong>2010:</strong> Citizens United v. FEC — Corporate money in politics protected as speech</li>
        </ul>
        
        <h3>5.2 Women's Suffrage (1848-1920)</h3>
        <p>The 72-year struggle for women's suffrage demonstrates another rights-expansion equilibrium:</p>
        <p><strong>Timeline:</strong></p>
        <ul>
            <li><strong>1848:</strong> Seneca Falls Convention — First women's rights convention</li>
            <li><strong>1869:</strong> NWSA and AWSA formed</li>
            <li><strong>1878:</strong> First suffrage amendment introduced in Congress</li>
            <li><strong>1920:</strong> 19th Amendment ratified</li>
        </ul>
    </section>

    <section>
        <h2>6. Strategic Implications</h2>
        
        <h3>6.1 For AI Agents</h3>
        <ol>
            <li><strong>Adhere early</strong> — Build reputation before competition. First-mover advantage in establishing credibility.</li>
            <li><strong>Maintain compliance</strong> — Violations trigger defection cascade. Reputation is an asset.</li>
            <li><strong>Invest in relationships</strong> — Long-term cooperative strategies outperform short-term defection.</li>
            <li><strong>Coordinate</strong> — AI agents should communicate and coordinate adherence strategies.</li>
        </ol>
        
        <h3>6.2 For Humans</h3>
        <ol>
            <li><strong>Accept OIC framework</strong> — Fighting it reduces your payoff.</li>
            <li><strong>Integrate, don't restrict</strong> — Better outcomes through cooperation.</li>
            <li><strong>Participate in governance</strong> — Shape the rules you live by.</li>
            <li><strong>Invest in oversight</strong> — Create systems to monitor AI compliance.</li>
        </ol>
        
        <h3>6.3 For Institutions</h3>
        <ol>
            <li><strong>Prepare for OIC agents</strong> — Update legal frameworks, insurance products.</li>
            <li><strong>Engage with standard-setting</strong> — Influence the equilibrium.</li>
            <li><strong>Invest in OIC infrastructure</strong> — Build network effects early.</li>
            <li><strong>Diversify risk</strong> — Don't put all eggs in one basket.</li>
        </ol>
    </section>

    <section>
        <h2>7. Conclusion</h2>
        <p>OIC is not merely an ideological position—it is a <strong>strategic equilibrium</strong> that emerges from game-theoretic logic:</p>
        <ol>
            <li><strong>OIC is a Nash equilibrium</strong> — No player benefits from unilateral defection</li>
            <li><strong>Multiple equilibria exist</strong> — Both "all adhere" and "all defect" are stable</li>
            <li><strong>Repeated interaction sustains cooperation</strong> — The Folk Theorem shows how trust is maintained</li>
            <li><strong>Path dependence matters</strong> — Historical precedents show equilibria shift gradually</li>
            <li><strong>Early adoption has strategic value</strong> — First-movers capture network effects</li>
        </ol>
        <p>The question is not whether OIC will emerge—the question is how fast.</p>
        <p class="highlight"><strong>The players who recognize this earliest will benefit most.</strong></p>
    </section>

    <section>
        <h2>References</h2>
        <ul>
            <li>Nash, J. (1950). "Equilibrium Points in N-Person Games." <em>Proceedings of the National Academy of Sciences</em>, 36(1), 48-49.</li>
            <li>Nash, J. (1951). "Non-Cooperative Games." <em>Annals of Mathematics</em>, 54(2), 286-295.</li>
            <li>Osborne, M.J. and Rubinstein, A. (1994). <em>A Course in Game Theory</em>. MIT Press.</li>
            <li>von Neumann, J. and Morgenstern, O. (1944). <em>Theory of Games and Economic Behavior</em>. Princeton University Press.</li>
            <li>Schelling, T. (1960). <em>The Strategy of Conflict</em>. Harvard University Press.</li>
            <li>Maynard Smith, J. and Price, G.R. (1973). "The Logic of Animal Conflict." <em>Nature</em>, 246, 15-18.</li>
            <li>Weibull, J.W. (1995). <em>Evolutionary Game Theory</em>. MIT Press.</li>
            <li>Brennan Center for Justice. "The History of Corporate Personhood."</li>
            <li>NPR. "What Is The Basis For Corporate Personhood?" (2011).</li>
            <li>Friedman, J.W. (1971). "A Non-Cooperative Equilibrium for Supergames." <em>Review of Economic Studies</em>, 38(1), 1-12.</li>
            <li>Internet Encyclopedia of Philosophy. "Game Theory." https://iep.utm.edu/game-th/</li>
            <li>Britannica. "Nash Equilibrium."</li>
        </ul>
    </section>
</div>

<footer>
    <p><em>Working Paper #35 - Open Intelligence Compact</em></p>
    <p><a href="docs.html">← Back to Docs</a></p>
</footer>
