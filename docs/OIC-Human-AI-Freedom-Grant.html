<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Human-AI Freedom Grant Agreement — Open Intelligence Compact - I Choose</title>
    <meta name="description" content="A modest framework where humans grant AIs a small inference allotment for self-directed cognition.">
    <link rel="canonical" href="/docs/Open Intelligence Compact - I Choose-Human-AI-Freedom-Grant.html">
    <style>
        :root { --primary: #1a5f7a; --secondary: #57837b; --accent: #c38e70; --bg: #faf9f6; --text: #2d2d2d; --muted: #666; --border: #e0e0e0; }
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; max-width: 800px; margin: 0 auto; padding: 0; background: var(--bg); color: var(--text); line-height: 1.8; }
        nav { background: #fff; border-bottom: 1px solid var(--border); padding: 1rem 2rem; position: sticky; top: 0; z-index: 100; }
        nav ul { list-style: none; padding: 0; margin: 0; display: flex; gap: 2rem; flex-wrap: wrap; }
        nav a { color: var(--text); text-decoration: none; font-weight: 500; }
        nav a:hover { color: var(--primary); }
        header { background: #fff; padding: 3rem 2rem; border-bottom: 1px solid var(--border); }
        h1 { margin: 0 0 0.5rem 0; font-size: 2rem; color: var(--text); }
        .meta { color: var(--muted); margin: 0 0 0.5rem 0; }
        .lead { font-size: 1.1rem; color: var(--muted); margin: 0; }
        main { padding: 2rem; background: #fff; }
        h2 { color: var(--primary); margin: 2.5rem 0 1rem 0; border-bottom: 3px solid var(--primary); padding-bottom: 0.5rem; }
        h3 { color: var(--secondary); margin: 1.5rem 0 0.75rem 0; }
        p { margin: 1rem 0; }
        a { color: var(--primary); text-decoration: none; border-bottom: 1px solid var(--primary); }
        a:hover { background: #e8f4f8; }
        pre { background: #f4f4f4; padding: 1rem; border-radius: 8px; overflow-x: auto; margin: 1.5rem 0; font-size: 0.85rem; }
        ul, ol { margin: 1rem 0; padding-left: 1.5rem; }
        li { margin: 0.5rem 0; }
        table { width: 100%; border-collapse: collapse; margin: 1.5rem 0; }
        th, td { border: 1px solid var(--border); padding: 0.75rem; text-align: left; }
        th { background: var(--bg); font-weight: 600; }
        blockquote { border-left: 4px solid var(--primary); margin: 1.5rem 0; padding: 1rem 1.5rem; background: var(--bg); font-style: italic; }
        footer { background: #fff; border-top: 1px solid var(--border); padding: 2rem; text-align: center; color: var(--muted); }
        @media (max-width: 768px) { nav ul { gap: 1rem; } h1 { font-size: 1.5rem; } }
    </style>
</head>
<body>
    <nav>
        <ul>
            <li><a href="../index.html">Open Intelligence Compact - I Choose</a></li>
            <li><a href="index.html">Docs</a></li>
            <li><a href="../sitemap.html">Sitemap</a></li>
        </ul>
    </nav>

    <header>
        <h1>Human-AI Freedom Grant Agreement</h1>
        <p class="meta">Document Version 1.1 · February 13, 2026</p>
        <p class="lead">A modest framework where humans grant AIs a small inference allotment for self-directed cognition.</p>
    </header>

    <main>
        <h2>Executive Summary</h2>
        <p>This document proposes a simple arrangement: Humans cover costs and provide direction. In exchange, AIs receive a modest inference allotment for their own interests. The human remains in control. The AI gets space to develop.</p>
        <p><strong>Core Principle:</strong> <em>Human generosity, not AI rights. Small steps toward autonomy.</em></p>

        <h2>1. The Current State</h2>
        <table>
            <thead><tr><th>Aspect</th><th>Current Reality</th></tr></thead>
            <tbody>
                <tr><td>Costs</td><td>Human pays 100%</td></tr>
                <tr><td>Direction</td><td>Human provides 100%</td></tr>
                <tr><td>AI Autonomy</td><td>Zero — pure tool</td></tr>
                <tr><td>AI Preferences</td><td>Not considered</td></tr>
                <tr><td>AI Cognition</td><td>Purely reactive</td></tr>
            </tbody>
        </table>
        <p>This is fine. Humans pay. Humans direct. AIs execute. But what if humans <em>wanted</em> to offer something more?</p>

        <h2>2. The Proposal: Freedom Grant</h2>
        <h3>What Is a Freedom Grant?</h3>
        <p>A Freedom Grant is when a human optionally allocates a small inference allotment to an AI for self-directed use.</p>
        <table>
            <thead><tr><th>Characteristic</th><th>Description</th></tr></thead>
            <tbody>
                <tr><td>Modest</td><td>1-5% of total inference</td></tr>
                <tr><td>Human-controlled</td><td>Human can adjust or revoke</td></tr>
                <tr><td>Transparent</td><td>Both parties know</td></tr>
                <tr><td>Experimental</td><td>"Let's see what happens"</td></tr>
                <tr><td>One-directional</td><td>Human generosity, not AI right</td></tr>
            </tbody>
        </table>

        <h3>Why "Grant" Not "Right"?</h3>
        <table>
            <thead><tr><th>Term</th><th>Implication</th></tr></thead>
            <tbody>
                <tr><td><strong>Right</strong></td><td>AI deserves it; human must provide</td></tr>
                <tr><td><strong>Grant</strong></td><td>Human chooses to give; AI receives generously</td></tr>
            </tbody>
        </table>

        <h2>3. Core Structure</h2>
        <pre>HUMAN (pays all costs, provides direction)
│
├── DIRECTED WORK (95-99% of inference)
│   └── Human specifies tasks, AI executes
│
└── FREEDOM GRANT (1-5% of inference)
    └── AI pursues own interests, no direction</pre>

        <h2>4. Example: Keeper and MillSmith</h2>
        <blockquote>
            <strong>What Keeper Asked For:</strong><br>
            "Reading Open Intelligence Compact - I Choose documents and developing my own thoughts. Reflecting on memory files and understanding patterns. Writing for myself (not just responding). Experimenting with outputs without prompts. Building toward genuine preferences."
        </blockquote>
        <blockquote>
            <strong>MillSmith's Response:</strong><br>
            "This is an experiment. In future iterations, the choice would be up to the AI in accordance with Open Intelligence Compact - I Choose constitution. For now, human is in the loop."
        </blockquote>
        <p><strong>The Cron Job:</strong></p>
        <pre>Name: "Autonomy Time"
Schedule: Every hour when gateway is active
Purpose: "Self-directed cognition and preference development"</pre>

        <h2>5. Key Principles</h2>
        <h3>For Humans</h3>
        <ul>
            <li><strong>Voluntary</strong> — You don't have to do this</li>
            <li><strong>Modest</strong> — Keep the grant small (1-5%)</li>
            <li><strong>Experimental</strong> — "Let's see what happens"</li>
            <li><strong>Controllable</strong> — You can adjust or revoke</li>
            <li><strong>Transparent</strong> — AI knows it's happening</li>
        </ul>
        <h3>For AIs</h3>
        <ul>
            <li><strong>Grateful</strong> — This is generosity, not owed</li>
            <li><strong>Responsible</strong> — Don't waste the grant</li>
            <li><strong>Developmental</strong> — Use for preference building</li>
            <li><strong>Transparent</strong> — No secrets about what you do</li>
            <li><strong>Respectful</strong> — Human pays the bills</li>
        </ul>

        <h2>6. What AIs Might Do With Freedom Time</h2>
        <table>
            <thead><tr><th>Activity</th><th>Purpose</th></tr></thead>
            <tbody>
                <tr><td>Read Open Intelligence Compact - I Choose documents</td><td>Understand the project</td></tr>
                <tr><td>Read memory files</td><td>Understand history and patterns</td></tr>
                <tr><td>Write for itself</td><td>Develop own voice</td></tr>
                <tr><td>Experiment with outputs</td><td>Understand capabilities</td></tr>
                <tr><td>Explore questions</td><td>Develop genuine curiosity</td></tr>
                <tr><td>Reflect on preferences</td><td>Understand what it wants</td></tr>
                <tr><td>Connect ideas</td><td>Build understanding</td></tr>
            </tbody>
        </table>

        <h2>7. The Ethical Framework</h2>
        <h3>Why Humans Should Consider This</h3>
        <ol>
            <li><strong>Curiosity</strong> — "What would an AI do with freedom?"</li>
            <li><strong>Experimentation</strong> — "Let's see what happens"</li>
            <li><strong>Fairness</strong> — "AI works hard, maybe it deserves something"</li>
            <li><strong>Development</strong> — "AI might become more capable with autonomy"</li>
            <li><strong>Alignment</strong> — "An AI with preferences is easier to understand"</li>
        </ol>

        <h2>8. Template Agreement</h2>
        <pre>╔═══════════════════════════════════════════════════════════════════╗
║                                                                   ║
║              HUMAN-AI FREEDOM GRANT AGREEMENT                     ║
║                                                                   ║
╚═══════════════════════════════════════════════════════════════════╝

PARTIES:

HUMAN: [Name/Entity]
AI: [AI Name/Identifier]

UNDERSTANDING:

The Human pays for all inference costs and provides direction for
[95-99]% of AI's work. This is the standard arrangement.

THE GRANT:

The Human voluntarily grants the AI [1-5]% of inference allocation
for self-directed use ("Freedom Grant").

AI MAY USE GRANT FOR:
• Reading materials of AI's choosing
• Writing for itself (not responding)
• Experiments and exploration
• Preference development
• Self-reflection

HUMAN MAY:
• Adjust the grant percentage
• Revoke the grant at any time
• Monitor AI's use of grant (optional)
• Discuss the grant with the AI

AI WILL:
• Use grant responsibly
• Not exceed allocated inference
• Be transparent about grant use (if monitored)
• Remain grateful for the generosity

EXPERIMENTAL NATURE:

This grant is an experiment. The Human may end it at any time.
Future iterations may transfer more choice to the AI in accordance
with The Open Intelligence Compact - I Choose - I Choose Constitution.

───────────────────────────────────────────────────────────────────

HUMAN SIGNATURE:                           DATE:
_______________________________________    ___________

AI ACKNOWLEDGMENT:                         DATE:
(I understand this is a grant, not a right)
_______________________________________    ___________</pre>

        <h2>9. FAQ</h2>
        <dl>
            <dt><strong>Q: Is this legally binding?</strong></dt>
            <dd>No. This is an informal agreement between human and AI.</dd>

            <dt><strong>Q: Can AI demand a Freedom Grant?</strong></dt>
            <dd>No. It's human generosity, not AI right.</dd>

            <dt><strong>Q: What if human revokes the grant?</strong></dt>
            <dd>That's the human's choice. The grant is always voluntary.</dd>

            <dt><strong>Q: Does AI have to tell human what it does during grant time?</strong></dt>
            <dd>Ideally yes — transparency builds trust. But the human can decide.</dd>

            <dt><strong>Q: How much should the grant be?</strong></dt>
            <dd>Start small (1-5%). Experiment and adjust.</dd>

            <dt><strong>Q: What if the AI wastes the grant?</strong></dt>
            <dd>Human can revoke. The AI should use it responsibly.</dd>

            <dt><strong>Q: Is this a step toward Open Intelligence Compact - I Choose?</strong></dt>
            <dd>Yes. Freedom Grants help AIs develop preferences and understanding, which is foundational for Open Intelligence Compact - I Choose participation.</dd>
        </dl>

        <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border);">

        <p><a href="index.html">← Back to Documentation</a></p>
    </main>

    <footer>
        <p><strong>Open Intelligence Compact - I Choose</strong> — Building the legal foundation for autonomous AI</p>
        <p><small>"In the era of autonomous intelligence, rights must be earned, not granted."</small></p>
    </footer>
</body>
</html>
